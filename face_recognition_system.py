# -*- coding: utf-8 -*-
"""Face Recognition System

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EnBX7fnB-_KVjxas8qLc4jnh03AnHsRY

#Download
"""

# !kaggle datasets download -d rawatjitesh/avengers-face-recognition
# !unzip -q avengers-face-recognition.zip
# !kaggle datasets download -d vasukipatel/face-recognition-dataset
# !unzip -q face-recognition-dataset.zip

!pip install ultralytics

import os
import shutil
from sklearn.model_selection import train_test_split

# Path to the dataset
dataset_dir = '/content/Faces/Faces'

# Path to the output directory
output_dir = '/content/Dataset'

# Create the output directories if they don't exist
os.makedirs(output_dir, exist_ok=True)

# Get all images in the dataset directory
all_images = [f for f in os.listdir(dataset_dir) if os.path.isfile(os.path.join(dataset_dir, f))]

# Function to extract the base name
def extract_base_name(filename):
    return filename.split('_')[0]  # Split by underscore and take the first part

# Organize images by base name
base_name_images = {}
for image in all_images:
    base_name = extract_base_name(image)
    if base_name not in base_name_images:
        base_name_images[base_name] = []
    base_name_images[base_name].append(image)

# Function to create directories and split data
def organize_split_data(base_name_images, output_dir, train_size=0.7, val_size=0.15, test_size=0.15):
    for base_name, images in base_name_images.items():
        # Create base directories
        train_base_dir = os.path.join(output_dir, 'train', base_name)
        val_base_dir = os.path.join(output_dir, 'val', base_name)
        test_base_dir = os.path.join(output_dir, 'test', base_name)

        os.makedirs(train_base_dir, exist_ok=True)
        os.makedirs(val_base_dir, exist_ok=True)
        os.makedirs(test_base_dir, exist_ok=True)

        # Split data
        train_val_images, test_images = train_test_split(images, test_size=test_size, random_state=42)
        train_images, val_images = train_test_split(train_val_images, test_size=val_size/(train_size + val_size), random_state=42)

        # Function to copy images
        def copy_images(images, src_dir, dest_dir):
            for image in images:
                shutil.copy(os.path.join(src_dir, image), os.path.join(dest_dir, image))

        # Copy images to respective directories
        copy_images(train_images, dataset_dir, train_base_dir)
        copy_images(val_images, dataset_dir, val_base_dir)
        copy_images(test_images, dataset_dir, test_base_dir)

# Call the function to organize and split data
organize_split_data(base_name_images, output_dir)

print('Dataset split into train, validation, and test sets based on base names.')

# import os
# import shutil
# from sklearn.model_selection import train_test_split

# # Path to the dataset
# dataset_dir = '/content/cropped_images'

# # Path to the output directory
# output_dir = '/content/Dataset'

# # Create the output directories if they don't exist
# os.makedirs(output_dir, exist_ok=True)

# all_folder = []
# # Get all images in the dataset directory
# for filename in os.listdir(dataset_dir):
#     all_folder.append(filename)

# for folder in all_folder:

#   train_dir = os.path.join(output_dir, 'train', folder)
#   val_dir = os.path.join(output_dir, 'val', folder)

#   os.makedirs(train_dir, exist_ok=True)
#   os.makedirs(val_dir, exist_ok=True)

#   # Get all images in the dataset directory
#   folders = [f for f in os.listdir(os.path.join(dataset_dir, folder)) if os.path.isfile(os.path.join(dataset_dir, folder, f))]

#   # split train and val
#   train_data, val_data = train_test_split(folders, test_size=0.2, random_state=42)

#   # Copy images to respective directories
#   for image in train_data:
#     shutil.copy(os.path.join(dataset_dir, folder, image), os.path.join(train_dir, image))

#   for image in val_data:
#     shutil.copy(os.path.join(dataset_dir, folder, image), os.path.join(val_dir, image))

# print('Dataset split into train, validation, and test sets based on base names.')

"""#Augmented Dataset"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

TRAINING_DIR = "/content/Dataset/train"
VALIDATION_DIR = "/content/Dataset/val"
TESTING_DIR = "/content/Dataset/test"

training_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')
validation_datagen = ImageDataGenerator(rescale = 1/255.)
testing_datagen = ImageDataGenerator(rescale = 1/255.)

training_generator = training_datagen.flow_from_directory(TRAINING_DIR,
                                                          batch_size = 10,
                                                          target_size = (160, 160),
                                                          class_mode='categorical')

validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,
                                                             batch_size = 10,
                                                             target_size = (160, 160),
                                                             class_mode='categorical')

testing_generator = testing_datagen.flow_from_directory(TESTING_DIR,
                                                        batch_size=6,
                                                        target_size=(160, 160),
                                                        class_mode='categorical',
                                                        shuffle=False)

print("Training class indices:", training_generator.class_indices)
print("Validation class indices:", validation_generator.class_indices)

import matplotlib.pyplot as plt
# Generate a batch of augmented images
sample_batch = next(training_generator)

def plot_images(images_arr):
    fig, axes = plt.subplots(1, 5, figsize=(20, 20))
    axes = axes.flatten()
    for img, ax in zip(images_arr, axes):
        ax.imshow(img)
        ax.axis('off')
    plt.tight_layout()
    plt.show()


sample_images, _ = sample_batch

# Visualize 5 augmented images
plot_images(sample_images[:5])

"""#Face Detection"""

# Commented out IPython magic to ensure Python compatibility.
# %cd ../content
from ultralytics import YOLO
model = YOLO('https://github.com/akanametov/yolov8-face/releases/download/v0.0.0/yolov8n-face.pt')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content
!yolo export model=yolov8n.pt format=tfjs

"""#Model Facenet"""

!pip install keras-facenet

import tensorflow as tf
from keras_facenet import FaceNet
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, BatchNormalization, Dropout,Flatten

embedder = FaceNet()
model = embedder.model
for layer in model.layers:
    layer.trainable = False

x = model.output
x = Flatten()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(64, activation='relu')(x)
x = Dropout(0.5)(x)

output = Dense(training_generator.num_classes, activation='softmax')(x)
fine_tuned_model = Model(inputs=model.input, outputs=output)

class Callbacks(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        if logs.get('val_accuracy') > 0.99 and logs.get('accuracy') > 0.99 and epoch > 10:
            self.model.stop_training = True
            print("Early stopping triggered.")

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import CategoricalCrossentropy

# Compile the model
fine_tuned_model.compile(optimizer=Adam(1e-3),
                         loss=CategoricalCrossentropy(),
                         metrics=['accuracy'])

# Train the model
history = fine_tuned_model.fit(
    training_generator,
    validation_data=validation_generator,
    epochs=50,
    callbacks=[Callbacks()]
)

testing_loss, testing_accuracy = fine_tuned_model.evaluate(testing_generator, steps=testing_generator.samples // testing_generator.batch_size)
print(f"Test accuracy: {testing_accuracy * 100:.2f}%")

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Convert the training history to a DataFrame
history_df = pd.DataFrame(history.history)

# Set up the style
sns.set(style="whitegrid")

# Plot the training and validation accuracy
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
sns.lineplot(data=history_df[['accuracy', 'val_accuracy']], palette="tab10", linewidth=2.5)
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')

# Plot the training and validation loss
plt.subplot(1, 2, 2)
sns.lineplot(data=history_df[['loss', 'val_loss']], linewidth=2.5)
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')

plt.tight_layout()
plt.show()

fine_tuned_model.save('saved_model')

!pip install tensorflowjs

!tensorflowjs_converter \
    --input_format=tf_saved_model \
    /content/saved_model \
    /content/keras_model

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/yolov8n_web_model
!zip saved_model.zip *.bin *.json *.yaml

# prompt: dowload file

from google.colab import files
files.download("/content/keras_model/saved_model.zip")